{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfqjyfVm5l75",
        "outputId": "7c29df94-f2e0-41ee-888d-87b1439f828c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data generation...\n",
            "\n",
            "1. Creating large_sales_data.csv...\n",
            "   ✓ Created with 1,000,000 rows (81.5 MB)\n",
            "2. Creating customers.csv...\n",
            "   ✓ Created with 500,000 rows and 11 columns\n",
            "3. Creating ratings.csv...\n",
            "   ✓ Created with 2,000,000 rows\n",
            "4. Creating products.csv...\n",
            "   ✓ Created with 5,000,000 rows\n",
            "5. Creating transactions.csv...\n",
            "   ✓ Created with 3,000,000 rows\n",
            "6. Creating orders.csv...\n",
            "   ✓ Created with 2,500,000 rows\n",
            "\n",
            "============================================================\n",
            "DATA GENERATION COMPLETE!\n",
            "============================================================\n",
            "✓ large_sales_data.csv               32.5 MB\n",
            "✓ customers.csv                      50.0 MB\n",
            "✓ ratings.csv                        45.4 MB\n",
            "✓ products.csv                      124.8 MB\n",
            "✓ transactions.csv                   86.5 MB\n",
            "✓ orders.csv                         90.5 MB\n",
            "============================================================\n",
            "Total size: 429.6 MB\n",
            "\n",
            "You can now run the tutorial examples with these files!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Sample Data Generator for Large Dataset Tutorial\n",
        "Run this script to create the sample CSV files used in the tutorial examples.\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "\n",
        "print(\"Starting data generation...\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1. Generate large_sales_data.csv (for chunking example)\n",
        "# ============================================================================\n",
        "print(\"1. Creating large_sales_data.csv...\")\n",
        "\n",
        "num_rows = 1_000_000  # 1 million rows\n",
        "np.random.seed(42)\n",
        "\n",
        "sales_data = {\n",
        "    'transaction_id': range(1, num_rows + 1),\n",
        "    'date': [datetime(2024, 1, 1) + timedelta(days=random.randint(0, 365))\n",
        "             for _ in range(num_rows)],\n",
        "    'revenue': np.random.uniform(10, 1000, num_rows).round(2),\n",
        "    'product_id': np.random.randint(1, 1000, num_rows),\n",
        "    'region': np.random.choice(['North', 'South', 'East', 'West'], num_rows)\n",
        "}\n",
        "\n",
        "df_sales = pd.DataFrame(sales_data)\n",
        "df_sales.to_csv('large_sales_data.csv', index=False)\n",
        "print(f\"   ✓ Created with {num_rows:,} rows ({df_sales.memory_usage(deep=True).sum() / 1024**2:.1f} MB)\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. Generate customers.csv (for column selection example)\n",
        "# ============================================================================\n",
        "print(\"2. Creating customers.csv...\")\n",
        "\n",
        "num_customers = 500_000\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create lots of columns (but we'll only use a few in the tutorial)\n",
        "customers_data = {\n",
        "    'customer_id': range(1, num_customers + 1),\n",
        "    'age': np.random.randint(18, 80, num_customers),\n",
        "    'purchase_amount': np.random.uniform(5, 500, num_customers).round(2),\n",
        "    'first_name': [f'User{i}' for i in range(num_customers)],\n",
        "    'last_name': [f'Lastname{i}' for i in range(num_customers)],\n",
        "    'email': [f'user{i}@example.com' for i in range(num_customers)],\n",
        "    'phone': [f'555-{random.randint(1000, 9999)}' for _ in range(num_customers)],\n",
        "    'address': [f'{random.randint(1, 9999)} Main St' for _ in range(num_customers)],\n",
        "    'city': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston'], num_customers),\n",
        "    'state': np.random.choice(['NY', 'CA', 'IL', 'TX'], num_customers),\n",
        "    'zip_code': [f'{random.randint(10000, 99999)}' for _ in range(num_customers)],\n",
        "}\n",
        "\n",
        "df_customers = pd.DataFrame(customers_data)\n",
        "df_customers.to_csv('customers.csv', index=False)\n",
        "print(f\"   ✓ Created with {num_customers:,} rows and {len(customers_data)} columns\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. Generate ratings.csv (for data type optimization)\n",
        "# ============================================================================\n",
        "print(\"3. Creating ratings.csv...\")\n",
        "\n",
        "num_ratings = 2_000_000\n",
        "np.random.seed(42)\n",
        "\n",
        "ratings_data = {\n",
        "    'user_id': np.random.randint(1, 100000, num_ratings),\n",
        "    'product_id': np.random.randint(1, 10000, num_ratings),\n",
        "    'rating': np.random.randint(1, 6, num_ratings),  # 1-5 stars\n",
        "    'timestamp': [datetime(2024, 1, 1) + timedelta(days=random.randint(0, 365))\n",
        "                  for _ in range(num_ratings)]\n",
        "}\n",
        "\n",
        "df_ratings = pd.DataFrame(ratings_data)\n",
        "df_ratings.to_csv('ratings.csv', index=False)\n",
        "print(f\"   ✓ Created with {num_ratings:,} rows\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. Generate products.csv (for categorical data example)\n",
        "# ============================================================================\n",
        "print(\"4. Creating products.csv...\")\n",
        "\n",
        "num_products = 5_000_000\n",
        "np.random.seed(42)\n",
        "\n",
        "# Only 20 unique categories to demonstrate categorical efficiency\n",
        "categories = ['Electronics', 'Clothing', 'Home & Garden', 'Sports', 'Books',\n",
        "              'Toys', 'Food', 'Beauty', 'Automotive', 'Health',\n",
        "              'Office', 'Pet Supplies', 'Baby', 'Jewelry', 'Tools',\n",
        "              'Music', 'Movies', 'Games', 'Crafts', 'Outdoor']\n",
        "\n",
        "products_data = {\n",
        "    'product_id': range(1, num_products + 1),\n",
        "    'category': np.random.choice(categories, num_products),\n",
        "    'price': np.random.uniform(5, 500, num_products).round(2),\n",
        "    'stock': np.random.randint(0, 1000, num_products)\n",
        "}\n",
        "\n",
        "df_products = pd.DataFrame(products_data)\n",
        "df_products.to_csv('products.csv', index=False)\n",
        "print(f\"   ✓ Created with {num_products:,} rows\")\n",
        "\n",
        "# ============================================================================\n",
        "# 5. Generate transactions.csv (for filtering example)\n",
        "# ============================================================================\n",
        "print(\"5. Creating transactions.csv...\")\n",
        "\n",
        "num_transactions = 3_000_000\n",
        "np.random.seed(42)\n",
        "\n",
        "# Mix of years 2022-2024\n",
        "transactions_data = {\n",
        "    'transaction_id': range(1, num_transactions + 1),\n",
        "    'year': np.random.choice([2022, 2023, 2024], num_transactions, p=[0.3, 0.3, 0.4]),\n",
        "    'customer_id': np.random.randint(1, 100000, num_transactions),\n",
        "    'amount': np.random.uniform(10, 1000, num_transactions).round(2),\n",
        "    'product_id': np.random.randint(1, 10000, num_transactions)\n",
        "}\n",
        "\n",
        "df_transactions = pd.DataFrame(transactions_data)\n",
        "df_transactions.to_csv('transactions.csv', index=False)\n",
        "print(f\"   ✓ Created with {num_transactions:,} rows\")\n",
        "\n",
        "# ============================================================================\n",
        "# 6. Generate orders.csv (for the practical example)\n",
        "# ============================================================================\n",
        "print(\"6. Creating orders.csv...\")\n",
        "\n",
        "num_orders = 2_500_000\n",
        "np.random.seed(42)\n",
        "\n",
        "orders_data = {\n",
        "    'order_id': range(1, num_orders + 1),\n",
        "    'product_id': np.random.randint(1, 5000, num_orders),\n",
        "    'quantity': np.random.randint(1, 10, num_orders),\n",
        "    'price': np.random.uniform(10, 500, num_orders).round(2),\n",
        "    'customer_id': np.random.randint(1, 100000, num_orders),\n",
        "    'order_date': [datetime(2024, 1, 1) + timedelta(days=random.randint(0, 365))\n",
        "                   for _ in range(num_orders)]\n",
        "}\n",
        "\n",
        "df_orders = pd.DataFrame(orders_data)\n",
        "df_orders.to_csv('orders.csv', index=False)\n",
        "print(f\"   ✓ Created with {num_orders:,} rows\")\n",
        "\n",
        "# ============================================================================\n",
        "# Summary\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATA GENERATION COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "files_created = [\n",
        "    'large_sales_data.csv',\n",
        "    'customers.csv',\n",
        "    'ratings.csv',\n",
        "    'products.csv',\n",
        "    'transactions.csv',\n",
        "    'orders.csv'\n",
        "]\n",
        "\n",
        "total_size = 0\n",
        "for filename in files_created:\n",
        "    import os\n",
        "    if os.path.exists(filename):\n",
        "        size_mb = os.path.getsize(filename) / 1024**2\n",
        "        total_size += size_mb\n",
        "        print(f\"✓ {filename:<30} {size_mb:>8.1f} MB\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"Total size: {total_size:.1f} MB\")\n",
        "print(\"\\nYou can now run the tutorial examples with these files!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define chunk size (number of rows per chunk)\n",
        "chunk_size = 100000\n",
        "total_revenue = 0\n",
        "\n",
        "# Read and process the file in chunks\n",
        "for chunk in pd.read_csv('large_sales_data.csv', chunksize=chunk_size):\n",
        "    # Process each chunk\n",
        "    total_revenue += chunk['revenue'].sum()\n",
        "\n",
        "print(f\"Total Revenue: ${total_revenue:,.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGJE478V5zdK",
        "outputId": "9eac3b93-bd91-488e-e9e2-874bd2a5ea29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Revenue: $505,331,140.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Only load the columns you actually need\n",
        "columns_to_use = ['customer_id', 'age', 'purchase_amount']\n",
        "\n",
        "df = pd.read_csv('customers.csv', usecols=columns_to_use)\n",
        "\n",
        "# Now work with a much lighter dataframe\n",
        "average_purchase = df.groupby('age')['purchase_amount'].mean()\n",
        "print(average_purchase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z18CqsiP6YzY",
        "outputId": "f068b308-f680-4b50-be44-f2e8c517977b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age\n",
            "18    252.514034\n",
            "19    252.430570\n",
            "20    251.067513\n",
            "21    255.589238\n",
            "22    252.758337\n",
            "         ...    \n",
            "75    251.947672\n",
            "76    252.316683\n",
            "77    252.169300\n",
            "78    252.327017\n",
            "79    251.329695\n",
            "Name: purchase_amount, Length: 62, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# First, let's see the default memory usage\n",
        "df = pd.read_csv('ratings.csv')\n",
        "print(\"Default memory usage:\")\n",
        "print(df.memory_usage(deep=True))\n",
        "\n",
        "# Now optimize the data types\n",
        "df['rating'] = df['rating'].astype('int8')  # Ratings are 1-5, so int8 is enough\n",
        "df['user_id'] = df['user_id'].astype('int32')  # Assuming user IDs fit in int32\n",
        "\n",
        "print(\"\\nOptimized memory usage:\")\n",
        "print(df.memory_usage(deep=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNaEqR--6clD",
        "outputId": "3a3241b1-d6da-4558-8104-62e9669b364b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default memory usage:\n",
            "Index               132\n",
            "user_id        16000000\n",
            "product_id     16000000\n",
            "rating         16000000\n",
            "timestamp     118000000\n",
            "dtype: int64\n",
            "\n",
            "Optimized memory usage:\n",
            "Index               132\n",
            "user_id         8000000\n",
            "product_id     16000000\n",
            "rating          2000000\n",
            "timestamp     118000000\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('products.csv')\n",
        "\n",
        "# Check memory before conversion\n",
        "print(f\"Before: {df['category'].memory_usage(deep=True) / 1024**2:.2f} MB\")\n",
        "\n",
        "# Convert to category\n",
        "df['category'] = df['category'].astype('category')\n",
        "\n",
        "# Check memory after conversion\n",
        "print(f\"After: {df['category'].memory_usage(deep=True) / 1024**2:.2f} MB\")\n",
        "\n",
        "# It still works like normal text\n",
        "print(df['category'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsC9oxox6hoz",
        "outputId": "7b0da9fe-7c34-43ad-b238-dabe88b488b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: 266.07 MB\n",
            "After: 4.77 MB\n",
            "category\n",
            "Games            250888\n",
            "Music            250668\n",
            "Toys             250470\n",
            "Clothing         250236\n",
            "Office           250214\n",
            "Outdoor          250134\n",
            "Beauty           250107\n",
            "Food             250061\n",
            "Jewelry          250016\n",
            "Pet Supplies     249992\n",
            "Tools            249970\n",
            "Books            249960\n",
            "Home & Garden    249919\n",
            "Baby             249852\n",
            "Movies           249824\n",
            "Sports           249782\n",
            "Crafts           249627\n",
            "Automotive       249534\n",
            "Health           249434\n",
            "Electronics      249312\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read in chunks and filter\n",
        "chunk_size = 100000\n",
        "filtered_chunks = []\n",
        "\n",
        "for chunk in pd.read_csv('transactions.csv', chunksize=chunk_size):\n",
        "    # Filter each chunk before storing it\n",
        "    filtered = chunk[chunk['year'] == 2024]\n",
        "    filtered_chunks.append(filtered)\n",
        "\n",
        "# Combine the filtered chunks\n",
        "df_2024 = pd.concat(filtered_chunks, ignore_index=True)\n",
        "\n",
        "print(f\"Loaded {len(df_2024)} rows from 2024\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL8Xfkma6pEX",
        "outputId": "c06777e0-aa4f-4864-e964-c834bfbf558e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1199749 rows from 2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "\n",
        "# Read with Dask (it handles chunking automatically)\n",
        "df = dd.read_csv('large_sales_data.csv')\n",
        "\n",
        "# Operations look just like pandas\n",
        "result = df['revenue'].mean()\n",
        "\n",
        "# Dask is lazy—compute() actually executes the calculation\n",
        "average_sales = result.compute()\n",
        "\n",
        "print(f\"Average Sales: ${average_sales:,.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4iEMOF37L6N",
        "outputId": "6595c451-7a9f-4728-bdc6-675e88babae2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sales: $505.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read just the first 50,000 rows\n",
        "df_sample = pd.read_csv('large_sales_data.csv', nrows=50000)\n",
        "\n",
        "# Or read a random sample using skiprows\n",
        "import random\n",
        "skip_rows = lambda x: x > 0 and random.random() > 0.01  # Keep ~1% of rows\n",
        "\n",
        "df_random_sample = pd.read_csv('large_sales_data.csv', skiprows=skip_rows)\n",
        "\n",
        "print(f\"Sample size: {len(df_random_sample)} rows\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTs0_BT07OcV",
        "outputId": "617f86e9-b023-4417-b4a3-1aafc0fcfe41"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample size: 10200 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZBwm5jlr7flr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}